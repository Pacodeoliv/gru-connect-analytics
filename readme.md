

# GRU Connect Analytics âœˆï¸ğŸ“Š

O **GRU Connect Analytics** Ã© uma plataforma de Engenharia de Dados ponta a ponta (E2E) projetada para analisar o risco de conexÃµes de passageiros no Aeroporto Internacional de Guarulhos (GRU/SBGR).

O projeto transforma dados brutos da ANAC em inteligÃªncia logÃ­stica, permitindo identificar gargalos operacionais e janelas crÃ­ticas de conexÃ£o atravÃ©s de um pipeline moderno e escalÃ¡vel.

---

## ğŸ—ï¸ Arquitetura do Projeto

O pipeline segue os princÃ­pios de **Data Lakehouse** utilizando a arquitetura medalhÃ£o:

```mermaid
graph LR
    subgraph "External Sources"
        ANAC[ANAC VRA - CSV]
    end

    subgraph "Data Lakehouse (Medallion)"
        direction TB
        B[(Bronze Layer)] -- "PySpark (Cleaning)" --> S[(Silver Layer)]
        S -- "dbt (Modeling)" --> G[(Gold Layer)]
    end

    subgraph "Gold Tables (Star Schema)"
        G --> F[fato_conexoes]
        G --> D1[dim_aeroportos]
        G --> D2[dim_empresas] 
        G --> D3[fato_conexoes]
    end

    subgraph "Orchestration & Tools"
        Airflow[Airflow 3.0] -.-> B
        Airflow -.-> S
        Airflow -.-> G
        Poetry[Poetry] -.-> Airflow
    end

    ANAC --> B

```

---

## ğŸš€ Contexto de NegÃ³cio

O sucesso de um hub aeroportuÃ¡rio depende do **Minimum Connect Time (MCT)**. ConexÃµes com intervalo reduzido possuem alto risco de perda de voo. Este projeto identifica essas janelas crÃ­ticas cruzando dados oficiais da ANAC (VRA), permitindo uma visÃ£o preditiva sobre a eficiÃªncia logÃ­stica das companhias aÃ©reas.

### ğŸ”§ LÃ³gica de NegÃ³cio (MCT Risk)

A tabela `fato_conexoes` classifica automaticamente cada par de voos baseado no tempo em solo:

* ğŸ”´ **RISCO CRÃTICO:** Janela de conexÃ£o inferior a 60 minutos.
* ğŸŸ¡ **RISCO MÃ‰DIO:** Janela de conexÃ£o entre 60 e 120 minutos.
* ğŸŸ¢ **SEGURO:** Janela de conexÃ£o superior a 120 minutos.

> **VisualizaÃ§Ã£o do Output Final (Camada Gold):**
> *Exemplo de processamento indicando o nÃ­vel de risco por conexÃ£o.*

---

## ğŸ› ï¸ Stack TecnolÃ³gica

| Componente | Tecnologia |
| --- | --- |
| **Engine de Processamento** | Apache Spark (PySpark) |
| **Modelagem AnalÃ­tica** | dbt-spark (v1.11) |
| **Orquestrador** | Apache Airflow 3.0 (Standalone mode) |
| **Gerenciador de Pacotes** | Poetry |
| **Linguagem** | Python 3.10+ |
| **Formato de Arquivo** | Parquet |

---

## âœ… OrquestraÃ§Ã£o (Airflow 3.0)

O pipeline Ã© totalmente automatizado via Airflow, garantindo a execuÃ§Ã£o sequencial e o tratamento de erros em cada camada (Bronze â¡ï¸ Silver â¡ï¸ Gold).

> **VisualizaÃ§Ã£o da DAG (Graph View):**
> *Fluxo de tarefas automatizado garantindo a integridade do Lakehouse.*

---

## ğŸ“– DocumentaÃ§Ã£o e Linhagem (dbt)

Para garantir a transparÃªncia e governanÃ§a, utilizamos a documentaÃ§Ã£o nativa do dbt, que gera o dicionÃ¡rio de dados e o grafo de linhagem automÃ¡tica.

> **Grafo de Linhagem (Lineage Graph):**
> *Rastreabilidade completa desde os dados crus atÃ© os indicadores de negÃ³cio.*

### Como visualizar a documentaÃ§Ã£o localmente:

```bash
cd dbt_gru
poetry run dbt docs generate
poetry run dbt docs serve --port 8081

```

---

## âš™ï¸ Como Executar

### 1. InstalaÃ§Ã£o

```bash
# Clonar o repositÃ³rio
git clone https://github.com/paco-saavedra/gru-connect-analytics.git
cd gru-connect-analytics

# Instalar dependÃªncias com Poetry
poetry install

```

### 2. Subir Airflow

```bash
export AIRFLOW_HOME=$(pwd)/airflow
poetry run airflow standalone

```

* **URL:** `localhost:8080`
* **User:** `admin`
* **Password:** `admin`

---

## ğŸ‘¨â€ğŸ’» Autor

**Paco de Oliveira Saavedra**
Este projeto foi desenvolvido como um portfÃ³lio de Engenharia de Dados avanÃ§ada.

